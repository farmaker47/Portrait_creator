{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U2Net_to_TFLite.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UddOkPzVcG7u"
      },
      "source": [
        "# Install and import packages\n",
        "!pip install onnx\n",
        "!pip install onnxruntime\n",
        "!pip install pip install git+https://github.com/onnx/onnx-tensorflow.git\n",
        "\n",
        "\n",
        "import gdown\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "from torchvision import models\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from collections import OrderedDict\n",
        "import onnx\n",
        "import onnxruntime\n",
        "from onnx_tf.backend import prepare\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from skimage import io, transform, color\n",
        "from PIL import Image\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8yr4TqFwVfH"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3gyVJSFcPZc"
      },
      "source": [
        "# Download link from google drive link\n",
        "# https://drive.google.com/file/d/1IG3HdpcRiDoWNookbncQjeaPN28t90yW/view?usp=sharing\n",
        "# This is the model for portrait generation\n",
        "!gdown --id 1IG3HdpcRiDoWNookbncQjeaPN28t90yW"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66y8VQWWc6xR"
      },
      "source": [
        "# Model class for U2NET\n",
        "class REBNCONV(nn.Module):\n",
        "    def __init__(self,in_ch=3,out_ch=3,dirate=1):\n",
        "        super(REBNCONV,self).__init__()\n",
        "\n",
        "        self.conv_s1 = nn.Conv2d(in_ch,out_ch,3,padding=1*dirate,dilation=1*dirate)\n",
        "        self.bn_s1 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu_s1 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "        xout = self.relu_s1(self.bn_s1(self.conv_s1(hx)))\n",
        "\n",
        "        return xout\n",
        "\n",
        "## upsample tensor 'src' to have the same spatial size with tensor 'tar'\n",
        "def _upsample_like(src,tar):\n",
        "\n",
        "    src = F.upsample(src,size=tar.shape[2:],mode='bilinear')\n",
        "\n",
        "    return src\n",
        "\n",
        "\n",
        "### RSU-7 ###\n",
        "class RSU7(nn.Module):#UNet07DRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU7,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool4 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool5 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv7 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "\n",
        "        self.rebnconv6d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv5d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "        hx = self.pool4(hx4)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx)\n",
        "        hx = self.pool5(hx5)\n",
        "\n",
        "        hx6 = self.rebnconv6(hx)\n",
        "\n",
        "        hx7 = self.rebnconv7(hx6)\n",
        "\n",
        "        hx6d =  self.rebnconv6d(torch.cat((hx7,hx6),1))\n",
        "        hx6dup = _upsample_like(hx6d,hx5)\n",
        "\n",
        "        hx5d =  self.rebnconv5d(torch.cat((hx6dup,hx5),1))\n",
        "        hx5dup = _upsample_like(hx5d,hx4)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5dup,hx4),1))\n",
        "        hx4dup = _upsample_like(hx4d,hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = _upsample_like(hx3d,hx2)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = _upsample_like(hx2d,hx1)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "### RSU-6 ###\n",
        "class RSU6(nn.Module):#UNet06DRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU6,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool4 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "\n",
        "        self.rebnconv5d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "        hx = self.pool4(hx4)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx)\n",
        "\n",
        "        hx6 = self.rebnconv6(hx5)\n",
        "\n",
        "\n",
        "        hx5d =  self.rebnconv5d(torch.cat((hx6,hx5),1))\n",
        "        hx5dup = _upsample_like(hx5d,hx4)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5dup,hx4),1))\n",
        "        hx4dup = _upsample_like(hx4d,hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = _upsample_like(hx3d,hx2)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = _upsample_like(hx2d,hx1)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "### RSU-5 ###\n",
        "class RSU5(nn.Module):#UNet05DRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU5,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "\n",
        "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx4)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5,hx4),1))\n",
        "        hx4dup = _upsample_like(hx4d,hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = _upsample_like(hx3d,hx2)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = _upsample_like(hx2d,hx1)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "### RSU-4 ###\n",
        "class RSU4(nn.Module):#UNet04DRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU4,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4,hx3),1))\n",
        "        hx3dup = _upsample_like(hx3d,hx2)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = _upsample_like(hx2d,hx1)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "### RSU-4F ###\n",
        "class RSU4F(nn.Module):#UNet04FRES(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU4F,self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
        "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
        "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=4)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=8)\n",
        "\n",
        "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=4)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=2)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx2 = self.rebnconv2(hx1)\n",
        "        hx3 = self.rebnconv3(hx2)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4,hx3),1))\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3d,hx2),1))\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2d,hx1),1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "\n",
        "##### U^2-Net ####\n",
        "class U2NET(nn.Module):\n",
        "\n",
        "    def __init__(self,in_ch=3,out_ch=1):\n",
        "        super(U2NET,self).__init__()\n",
        "\n",
        "        self.stage1 = RSU7(in_ch,32,64)\n",
        "        self.pool12 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage2 = RSU6(64,32,128)\n",
        "        self.pool23 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage3 = RSU5(128,64,256)\n",
        "        self.pool34 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage4 = RSU4(256,128,512)\n",
        "        self.pool45 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage5 = RSU4F(512,256,512)\n",
        "        self.pool56 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
        "\n",
        "        self.stage6 = RSU4F(512,256,512)\n",
        "\n",
        "        # decoder\n",
        "        self.stage5d = RSU4F(1024,256,512)\n",
        "        self.stage4d = RSU4(1024,128,256)\n",
        "        self.stage3d = RSU5(512,64,128)\n",
        "        self.stage2d = RSU6(256,32,64)\n",
        "        self.stage1d = RSU7(128,16,64)\n",
        "\n",
        "        self.side1 = nn.Conv2d(64,out_ch,3,padding=1)\n",
        "        self.side2 = nn.Conv2d(64,out_ch,3,padding=1)\n",
        "        self.side3 = nn.Conv2d(128,out_ch,3,padding=1)\n",
        "        self.side4 = nn.Conv2d(256,out_ch,3,padding=1)\n",
        "        self.side5 = nn.Conv2d(512,out_ch,3,padding=1)\n",
        "        self.side6 = nn.Conv2d(512,out_ch,3,padding=1)\n",
        "\n",
        "        self.outconv = nn.Conv2d(6*out_ch,out_ch,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        #stage 1\n",
        "        hx1 = self.stage1(hx)\n",
        "        hx = self.pool12(hx1)\n",
        "\n",
        "        #stage 2\n",
        "        hx2 = self.stage2(hx)\n",
        "        hx = self.pool23(hx2)\n",
        "\n",
        "        #stage 3\n",
        "        hx3 = self.stage3(hx)\n",
        "        hx = self.pool34(hx3)\n",
        "\n",
        "        #stage 4\n",
        "        hx4 = self.stage4(hx)\n",
        "        hx = self.pool45(hx4)\n",
        "\n",
        "        #stage 5\n",
        "        hx5 = self.stage5(hx)\n",
        "        hx = self.pool56(hx5)\n",
        "\n",
        "        #stage 6\n",
        "        hx6 = self.stage6(hx)\n",
        "        hx6up = _upsample_like(hx6,hx5)\n",
        "\n",
        "        #-------------------- decoder --------------------\n",
        "        hx5d = self.stage5d(torch.cat((hx6up,hx5),1))\n",
        "        hx5dup = _upsample_like(hx5d,hx4)\n",
        "\n",
        "        hx4d = self.stage4d(torch.cat((hx5dup,hx4),1))\n",
        "        hx4dup = _upsample_like(hx4d,hx3)\n",
        "\n",
        "        hx3d = self.stage3d(torch.cat((hx4dup,hx3),1))\n",
        "        hx3dup = _upsample_like(hx3d,hx2)\n",
        "\n",
        "        hx2d = self.stage2d(torch.cat((hx3dup,hx2),1))\n",
        "        hx2dup = _upsample_like(hx2d,hx1)\n",
        "\n",
        "        hx1d = self.stage1d(torch.cat((hx2dup,hx1),1))\n",
        "\n",
        "\n",
        "        #side output\n",
        "        d1 = self.side1(hx1d)\n",
        "\n",
        "        d2 = self.side2(hx2d)\n",
        "        d2 = _upsample_like(d2,d1)\n",
        "\n",
        "        d3 = self.side3(hx3d)\n",
        "        d3 = _upsample_like(d3,d1)\n",
        "\n",
        "        d4 = self.side4(hx4d)\n",
        "        d4 = _upsample_like(d4,d1)\n",
        "\n",
        "        d5 = self.side5(hx5d)\n",
        "        d5 = _upsample_like(d5,d1)\n",
        "\n",
        "        d6 = self.side6(hx6)\n",
        "        d6 = _upsample_like(d6,d1)\n",
        "\n",
        "        d0 = self.outconv(torch.cat((d1,d2,d3,d4,d5,d6),1))\n",
        "\n",
        "        return F.sigmoid(d0), F.sigmoid(d1), F.sigmoid(d2), F.sigmoid(d3), F.sigmoid(d4), F.sigmoid(d5), F.sigmoid(d6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgMC2bZUdO6f"
      },
      "source": [
        "net = U2NET()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejnIviiLdatG"
      },
      "source": [
        "# Load checkpoint and view network architecture\n",
        "net.load_state_dict(torch.load('/content/u2net_portrait.pth', map_location='cpu'))\n",
        "    \n",
        "net.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crv6Gsk4ef0K"
      },
      "source": [
        "# Upload woman.png, view details and resize to model input for portrait generation(512,512)\n",
        "image = cv2.imread('/content/woman.png')\n",
        "print(image.shape)\n",
        "image_resized = cv2.resize(image, (512,512), interpolation = cv2.INTER_AREA)\n",
        "print(image_resized.shape)\n",
        "#print(image_resized[:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sPhPfvEhJsy"
      },
      "source": [
        "# Use pre process from this example\n",
        "# https://github.com/xuebinqin/U-2-Net/blob/master/u2net_portrait_demo.py#L99\n",
        "\n",
        "# Normalize the input\n",
        "tmpImg = np.zeros((image_resized.shape[0],image_resized.shape[1],3))\n",
        "input = image_resized/np.max(image_resized)\n",
        "#print(input[:1])\n",
        "\n",
        "tmpImg[:,:,0] = (input[:,:,0]-0.406)/0.225\n",
        "tmpImg[:,:,1] = (input[:,:,1]-0.456)/0.224\n",
        "tmpImg[:,:,2] = (input[:,:,2]-0.485)/0.229\n",
        "\n",
        "# Transpose inputs\n",
        "tmpImg = tmpImg.transpose((2, 0, 1))\n",
        "tmpImg = tmpImg[np.newaxis,:,:,:]\n",
        "tmpImg = torch.from_numpy(tmpImg)\n",
        "# Convert numpy array to torch tensor\n",
        "tmpImg = tmpImg.type(torch.FloatTensor)\n",
        "\n",
        "tmpImg = Variable(tmpImg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvCRVS7xjmi4"
      },
      "source": [
        "# Do inference and get the result\n",
        " #We will use d1 from the 7 outputs\n",
        "d1,d2,d3,d4,d5,d6,d7 = net(tmpImg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6so06gsjHNN4"
      },
      "source": [
        "# Print some info\n",
        "print(d1.shape)\n",
        "print(d1[:,:,:1,:100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOAAGfUuC_AU"
      },
      "source": [
        "# Use below to view the output from the model\n",
        "# Use info from https://github.com/xuebinqin/U-2-Net/blob/master/u2net_portrait_test.py#L33\n",
        "# and https://github.com/xuebinqin/U-2-Net/blob/master/u2net_portrait_test.py#L25\n",
        "def normPRED(d):\n",
        "    ma = torch.max(d)\n",
        "    mi = torch.min(d)\n",
        "\n",
        "    dn = (d-mi)/(ma-mi)\n",
        "\n",
        "    return dn\n",
        "\n",
        "pred = 1.0 - d1[:,0,:,:]\n",
        "pred = normPRED(pred)\n",
        "\n",
        "def save_output(image_name,pred,d_dir):\n",
        "\n",
        "    predict = pred\n",
        "    predict = predict.squeeze()\n",
        "    predict_np = predict.cpu().data.numpy()\n",
        "\n",
        "    im = Image.fromarray(predict_np*255).convert('RGB')\n",
        "\n",
        "    pb_np = np.array(im)\n",
        "\n",
        "    im.save('woman_BW.png')\n",
        "\n",
        "save_output(\"woman\",pred,\"/content\")\n",
        "\n",
        "\n",
        "pil_im = Image.open('/content/woman_BW.png', 'r')\n",
        "imshow(np.asarray(pil_im))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cywIVqNMD4oo"
      },
      "source": [
        "# Convert the model from Pytorch to ONNX\n",
        "# adding info for input and output name to be used later with runSignature new TensorFlow Lite feature\n",
        "# More info here: https://analyticsindiamag.com/converting-a-model-from-pytorch-to-tensorflow-guide-to-onnx/\n",
        "dummy_input = Variable(torch.randn(1, 3, 512, 512))\n",
        "torch.onnx.export(net, dummy_input, \"portrait.onnx\", input_names = ['input'], output_names = ['output'])\n",
        "'''\n",
        "# Export the model\n",
        "torch.onnx.export(net,               # model being run\n",
        "                  tmpImg,            # model input (or a tuple for multiple inputs)\n",
        "                  \"portrait.onnx\",   # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=10,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output']  # the model's output names\n",
        "                  )\n",
        "print(\"Model converted succesfully\")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXcKg5Xwjowu"
      },
      "source": [
        "# Check model\n",
        "onnx_model = onnx.load(\"portrait.onnx\")\n",
        "onnx.checker.check_model(onnx_model)\n",
        "print(\"Model checked succesfully\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U6JLpW6LqRA"
      },
      "source": [
        "# Convert model from ONNX to TensorFlow\n",
        "# More info here: https://github.com/onnx/onnx-tensorflow\n",
        "onnx_model = onnx.load('portrait.onnx')\n",
        "tf_rep = prepare(onnx_model)\n",
        "tf_rep.export_graph('portrait')\n",
        "\n",
        "print(\"Model converted to tensorflow graph succesfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HKNIYDk_2XO"
      },
      "source": [
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('/content/portrait') # path to the SavedModel directory\n",
        "\n",
        "# IMPORTANT!!!!!!!!!!!!!!!!!\n",
        "# Dynamic range quantization\n",
        "# Model from 170MB down to 40MB BUT with a lot of time for inference inside colab and android\n",
        "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('portrait.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFqKWUx5-fTE"
      },
      "source": [
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"/content/portrait.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(output_details)\n",
        "\n",
        "# Prepare input\n",
        "imageInput = np.zeros((512,512,3))\n",
        "input = image_resized/np.max(image_resized)\n",
        "imageInput[:,:,0] = (input[:,:,0]-0.406)/0.225\n",
        "imageInput[:,:,1] = (input[:,:,1]-0.456)/0.224\n",
        "imageInput[:,:,2] = (input[:,:,2]-0.485)/0.229\n",
        "\n",
        "imageInput = imageInput.transpose((2, 0, 1))\n",
        "imageInput = tf.convert_to_tensor(imageInput, dtype=tf.float32)\n",
        "imageInput = tf.expand_dims(imageInput, axis=0)\n",
        "\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], imageInput)\n",
        "\n",
        "interpreter.invoke()\n",
        "\n",
        "# The function `get_tensor()` returns a copy of the tensor data.\n",
        "# Use `tensor()` in order to get a pointer to the tensor.\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(output_data.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QRK8NE3j5dM"
      },
      "source": [
        "Inference with TensorFlow's new feature RunSignature\n",
        "https://www.tensorflow.org/lite/guide/signatures#run_signatures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHMlc-G3ONal"
      },
      "source": [
        "# These info can be used inside an android app\n",
        "signatures = interpreter.get_signature_list()\n",
        "print(signatures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OryrFGnaOZpT"
      },
      "source": [
        "encode = interpreter.get_signature_runner('serving_default')\n",
        "encoded = encode(input=imageInput)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0IrwybSWkVc"
      },
      "source": [
        "print(encoded.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsmfYmumQ8qr"
      },
      "source": [
        "# Print some details of the \"1884\" output result \n",
        "print('Encoded result:', encoded[\"1884\"][:,:,:1,:100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvcimP-SSXxG"
      },
      "source": [
        "# Use last array of the output\n",
        "tmpImgTFLIte = torch.from_numpy(encoded[\"output\"])\n",
        "# convert numpy array to torch tensor\n",
        "tmpImgTFLIte = tmpImgTFLIte.type(torch.FloatTensor)\n",
        "\n",
        "tmpImgTFLIte = Variable(tmpImgTFLIte)\n",
        "\n",
        "def normPRED(d):\n",
        "    ma = torch.max(d)\n",
        "    mi = torch.min(d)\n",
        "\n",
        "    dn = (d-mi)/(ma-mi)\n",
        "\n",
        "    return dn\n",
        "\n",
        "pred = 1.0 - tmpImgTFLIte[:,0,:,:]\n",
        "pred = normPRED(pred)\n",
        "\n",
        "def save_output(image_name,pred,d_dir):\n",
        "\n",
        "    predict = pred\n",
        "    predict = predict.squeeze()\n",
        "    predict_np = predict.cpu().data.numpy()\n",
        "\n",
        "    im = Image.fromarray(predict_np*255).convert('RGB')\n",
        "\n",
        "    im.save('woman_BW_tflite.png')\n",
        "\n",
        "save_output(\"woman\", pred, \"/content\")\n",
        "\n",
        "pil_im = Image.open('/content/woman_BW_tflite.png', 'r')\n",
        "imshow(np.asarray(pil_im))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3InWN_vbaJ-3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}